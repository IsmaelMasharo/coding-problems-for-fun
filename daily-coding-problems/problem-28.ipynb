{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Daily Coding Problem: Problem #28 [Medium] - Palantir**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Write an algorithm to justify text. Given a sequence of words and an integer line length k, return a list of strings which represents each line, fully justified.\n",
    "\n",
    "More specifically, you should have as many words as possible in each line. There should be at least one space between each word. Pad extra spaces when necessary so that each line has exactly length k. Spaces should be distributed as equally as possible, with the extra spaces, if any, distributed starting from the left.\n",
    "\n",
    "If you can only fit one word on a line, then you should pad the right-hand side with spaces.\n",
    "\n",
    "Each word is guaranteed not to be longer than k.\n",
    "\n",
    "For example, given the list of words [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"] and k = 16, you should return the following:\n",
    "```\n",
    "```python\n",
    "[\"the  quick brown\", # 1 extra space on the left\n",
    "\"fox  jumps  over\", # 2 extra spaces distributed evenly\n",
    "\"the   lazy   dog\"] # 4 extra spaces distributed evenly\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dinamic Programming Steps###\n",
    "0. **Greedy approach:**\n",
    "    * Maximize the current line. \n",
    "    * Problem: It may not maximize the overall lines.\n",
    "\n",
    "\n",
    "1. **Subproblems Definition:**\n",
    "    * **Task:** Trying to fit as many words as possible in each line (== minimize the number of blank spaces).\n",
    "    * **Question:** For current word `i`, where should I start the next line? (in which of the j remaining words?).\n",
    "    * **# Subproblems:** for every item I'll ask the previous question, so **n subproblems (n=#words)**\n",
    "\n",
    "\n",
    "2. **Guess and define the Number of choices:**\n",
    "    * **Guess:** Refers to answer the question above. \n",
    "    * **# guesses (choices):** For current word i I have n - i choices to start the new line (remaining words). **Worst Case: n**\n",
    "\n",
    "\n",
    "3. **Recurrence Relationship:**\n",
    "    * **Approach**:\n",
    "      \n",
    "      In order to fit the maximum amount of words we are going to work with its complementary. Minimizing blank spaces.  \n",
    "      Punishing badness, aka, unnecesary white spaces per line.  \n",
    "      Given that the total sum of white spaces per configuration could be the same, we could take the sum of the square roots of white spaces per line. In case of latex, the use the sum of cubic roots.\n",
    "    * **Model:** \n",
    "      \n",
    "      Cost of starting line with at word **i** = Cost of starting next line at word **j** + badness(**i to j**).\n",
    "\n",
    "    ```python\n",
    "    # k = line lenght\n",
    "    # words = array of words\n",
    "    # w = total length of words in a line counting valid white spaces\n",
    "    # DP[i] = Cost of starting line with at word i\n",
    "    w = lambda i,j: sum(len(words[i])) for i in range(i, len(words)+j)\n",
    "    badness = lambda i,j: pow(k - w(i,j), 3) if k - w(i,j) >= 0 else inf\n",
    "    DP[i] = min(DP[j] + badness(i,j) for j in range(i, len(words) + j) if j fits in line)\n",
    "    ```\n",
    "\n",
    "\n",
    "4. **Topological Order:**\n",
    "    * Depends on the subproblem relationship order.  \n",
    "      **Forward (ascending):** Current answer depends from before answers. i -> j -> ...  \n",
    "      **Backward (descending):** Current answer depends from following answers. j -> i -> ...  \n",
    "      In this case we have a forward relationship. The current line badness (number of unnecesary white spaces) depends on which word will start the next line.\n",
    "\n",
    "\n",
    "5. **Solving Original Problem:**\n",
    "    * In order to solve the original problem is necesary to save the least cost starting word at each index.  \n",
    "    So, for every index in the list of words (for every word) I need to save the least cost next starting word position.  \n",
    "    For example, if for the first index (first word) I calculate the index of least cost next line starting word I would be able to solve the original problem by assembling lines with the best starting words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_words_in_line(words, page_width):\n",
    "    \n",
    "    line = ''\n",
    "    words_total_len = sum(len(word) for word in words)\n",
    "    number_of_dividers = (len(words) - 1)\n",
    "    total_len = words_total_len + number_of_dividers\n",
    "    remaining_len = page_width - total_len\n",
    "    dividers = [' ' for x in range(number_of_dividers)]\n",
    "    \n",
    "    for x in range(remaining_len):\n",
    "        index = x%number_of_dividers\n",
    "        dividers[index] += ' '\n",
    "    \n",
    "    dividers.append('\\n')\n",
    "    \n",
    "    for x in range(len(words)):\n",
    "        line += words[x] + dividers[x]\n",
    "    \n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each value of the `words_least_cost_indices_memo` represents `the index of the least cost next line starting word` at that index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating overall cost\n",
    "\n",
    "def justify_text_helper(starting_word_index, words, page_width, words_least_cost_indices):\n",
    "\n",
    "    # base case\n",
    "    if starting_word_index >= len(words): \n",
    "        return 0\n",
    "\n",
    "    # checking memo\n",
    "    if words_least_cost_indices[starting_word_index] != None:\n",
    "        return words_least_cost_indices[starting_word_index]\n",
    "\n",
    "    # divide\n",
    "    word_fits = True\n",
    "    words_traversed = False\n",
    "    words_in_line_guesses = []\n",
    "    line_len = len(words[starting_word_index])\n",
    "    next_starting_word_index = starting_word_index + 1\n",
    "\n",
    "    while word_fits and not words_traversed:\n",
    "        next_word_starting_cost = justify_text_helper(next_starting_word_index, words, page_width, words_least_cost_indices)\n",
    "        current_cost = pow(page_width - line_len, 3)\n",
    "        words_in_line_guesses.append(next_word_starting_cost + current_cost)\n",
    "        \n",
    "        if next_starting_word_index < len(words):\n",
    "            line_len += len(words[next_starting_word_index]) + 1\n",
    "            if line_len > page_width:\n",
    "                word_fits = False\n",
    "        else:\n",
    "            words_traversed = True\n",
    "\n",
    "        next_starting_word_index += 1\n",
    "\n",
    "    # conquer\n",
    "    minimum_cost = min(words_in_line_guesses)\n",
    "\n",
    "    # memoizing\n",
    "    best_next_starting_word_index = starting_word_index + 1 + words_in_line_guesses.index(minimum_cost)\n",
    "    words_least_cost_indices[starting_word_index] = best_next_starting_word_index\n",
    "\n",
    "    return minimum_cost\n",
    "\n",
    "def justify_line_words(words, page_width):\n",
    "    starting_word_index = 0\n",
    "    total_words = len(words)\n",
    "    words_least_cost_indices_memo = [None]*total_words\n",
    "    overall_cost = justify_text_helper(starting_word_index, words, page_width, words_least_cost_indices_memo)\n",
    "    \n",
    "    print('overall_minimum_cost', overall_cost)\n",
    "    print('words_least_cost_indices_memo', words_least_cost_indices_memo, '\\n')\n",
    "    \n",
    "    justify_text = ''\n",
    "    starting_word_index = 0\n",
    "    next_starting_word_index = words_least_cost_indices_memo[starting_word_index]\n",
    "\n",
    "    while next_starting_word_index <= total_words:\n",
    "\n",
    "        line = words[starting_word_index : next_starting_word_index]\n",
    "        justify_text += space_words_in_line(line, page_width)\n",
    "\n",
    "        if next_starting_word_index >= total_words: break\n",
    "        starting_word_index = next_starting_word_index\n",
    "        next_starting_word_index = words_least_cost_indices_memo[next_starting_word_index]\n",
    "\n",
    "    print(justify_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_minimum_cost 7\n",
      "words_least_cost_indices_memo [3, 4, 5, 6, 7, 8, 9, 9, 9] \n",
      "\n",
      "the  quick brown\n",
      "fox  jumps  over\n",
      "the   lazy   dog\n",
      "\n"
     ]
    }
   ],
   "source": [
    "justify_line_words([\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"], 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
